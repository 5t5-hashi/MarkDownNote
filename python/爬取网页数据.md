# 需要的包

## requests

`requests`包是用来模拟用户端的网络请求的，通过

```python
#导入request包
import requests
#模拟发送请求
response = requests.get(
        f'https://www.xiangha.com/caipu/', cookies=cookies, headers=headers)
content = response.text
code=response.status_code
#response.status_code	获取请求的状态码
#response.text			获取请求的html格式化
```

get或post等其他请求方法向服务器发起请求，第一个参数为请求地址，后面的参数可为请求头 `header`，`cookies`等等



## BeautifulSoup

`BeautifulSoup`包是用来解析`html`数据的

```python
from bs4 import BeautifulSoup
import requests
import re

response = requests.get(
        f'https://www.xiangha.com/caipu/', cookies=cookies, headers=headers)
content = response.text
soup = BeautifulSoup(content, "html.parser")

data1 = soup.find("p", attrs={"class": "name kw"})#查找第一个class类为name和kw的p标签
data2 = soup.find_all("p", attrs={"class": "name kw"})#查找所有class类为name和kw的p标签(可迭代)
print(data1.string)#p标签的内容
print(data2)#可迭代的对象

urls = re.findall('href="(.*?)"', data1)#利用re模块正则筛选出在href="和"中的链接地址
```



# 相关网址

通过复制请求链接的`cURL(bash模式)`粘贴到 [生成request请求代码的网站](https://curlconverter.com/#)，把代码直接考入到 `python`程序中就然后运行就能成功发送模拟请求了。



其他相关 `python`的学习内容在 [廖雪峰python教程中](https://www.liaoxuefeng.com/wiki/1016959663602400)

